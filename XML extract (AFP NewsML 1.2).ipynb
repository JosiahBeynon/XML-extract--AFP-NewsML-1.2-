{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Extracting NewsML Headlines with XML\n",
    "\n",
    "NewsML specifies a standard format for news articles, which is used in many news and\n",
    "media outlets. This notebook demonstrates how to extract headlines from an XML file\n",
    "using the [`xml.etree.ElementTree`](https://docs.python.org/3/library/xml.etree.elementtree.html) module.\n",
    "\n",
    "The project is based on the following job spec:\n",
    "> Need a simple Python script to periodically\n",
    "search through a given folder for XML files and\n",
    "parse them into a list of dicts. The list will be\n",
    "passed to a different component that creates\n",
    "an RSS service xml file, which already exists\n",
    "and is not required to be written.\n",
    ">\n",
    ">A sample of the folder to check is attached. It\n",
    "includes multiple formats, some of them with\n",
    "images attached. Some of the xml files will\n",
    "refer to images that were not added to the zip\n",
    "file to keep it small. The format has a spec\n",
    "(NewsML 1.2) and is documented here:\n",
    "https://www.afp.com/communication\n",
    "/iris/Guide_to_AFP_NewsML-G2.html\n",
    "Skeleton code for checking the folder and\n",
    "passing the data to the RSS service will be\n",
    "provided, but the parse function is what's\n",
    "missing.\n",
    ">\n",
    ">Required values to parse are:\n",
    ">* Headline\n",
    ">* Topic\n",
    ">* Tags\n",
    ">* Authors\n",
    ">* Date\n",
    ">* Content\n",
    ">* Location\n",
    "\n",
    "I'm focussing on text extraction. The images could also be added and passed by adding another function, but the method used would depend on the clients requirements. I wasn't able to have that discussion with them, so I'm ignoring that element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_author_or_provider(file_path):\n",
    "    '''Function to XML extract author information,\n",
    "      or provider information as a fallback'''\n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # First, try to find author information\n",
    "        for byline in root.iter('ByLine'):\n",
    "            author_name = byline.text\n",
    "            return author_name  # Return author name if found\n",
    "\n",
    "        # If author is not found, try to find provider information\n",
    "        for provider in root.iter('Provider'):\n",
    "            party = provider.find('Party')\n",
    "            if party is not None and 'FormalName' in party.attrib:\n",
    "                provider_name = party.attrib['FormalName']\n",
    "                return provider_name  # Return provider name if found\n",
    "\n",
    "        # Return None if neither author nor provider is found\n",
    "        return None\n",
    "\n",
    "    except ET.ParseError:\n",
    "        return \"XML Parse Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_headlines(root):\n",
    "    \"\"\"\n",
    "    Refactored function to parse the XML root to extract the headline or an alternative text\n",
    "    when the headline is not explicitly found.\n",
    "\n",
    "    Args:\n",
    "    root (Element): The root element of the parsed XML document.\n",
    "\n",
    "    Returns:\n",
    "    str: The extracted headline or alternative text, or an appropriate message if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Looking for the HeadLine tag within the NewsLines section\n",
    "        headline = root.find('.//NewsLines/HeadLine')\n",
    "        if headline is not None and headline.text is not None:\n",
    "            return headline.text.strip()\n",
    "        else:\n",
    "            # If the headline is not found or empty, look for the first paragraph in body.content\n",
    "            first_paragraph = root.find('.//body.content/p')\n",
    "            if first_paragraph is not None and first_paragraph.text is not None:\n",
    "                return first_paragraph.text.strip()\n",
    "            else:\n",
    "                return \"Headline or alternative text not found in the file.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing the XML: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(root):\n",
    "    \"\"\"\n",
    "    Extract news text from <DataContent> within <ContentItem> tags.\n",
    "\n",
    "    Args:\n",
    "    root (ET.Element): The root of the ET tree.\n",
    "\n",
    "    Returns:\n",
    "    str: The extracted news text.\n",
    "    \"\"\"\n",
    "    news_text = []\n",
    "\n",
    "    # Find all <ContentItem> tags and then extract text from <DataContent> <p> tags\n",
    "    for content_item in root.findall('.//ContentItem'):\n",
    "        for data_content in content_item.findall('.//DataContent'):\n",
    "            for p in data_content.findall('.//p'):\n",
    "                if p.text:\n",
    "                    news_text.append(p.text)\n",
    "\n",
    "    return '\\n'.join(news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_newsml_xml(file_path):\n",
    "    \"\"\"\n",
    "    Parse a NewsML XML file and extract the required information.\n",
    "\n",
    "    :param file_path: Path to the NewsML XML file.\n",
    "    :return: Dictionary with extracted data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Initialize data dictionary\n",
    "        news_data = {\n",
    "            'Headline': None,\n",
    "            'Topic': None,\n",
    "            'Tags': None,\n",
    "            'Authors': None,\n",
    "            'Date': None,\n",
    "            'Content': None,\n",
    "            'Location': None\n",
    "        }\n",
    "\n",
    "        # Extracting Headline\n",
    "        news_data['Headline'] = parse_headlines(root)\n",
    "\n",
    "        # Extracting Topic (NameLabel)\n",
    "        topic = root.find(\".//Identification/NameLabel\")\n",
    "        if topic is not None:\n",
    "            news_data['Topic'] = topic.text\n",
    "\n",
    "        # Extracting Tags (OfInterestTo)\n",
    "        tags = root.findall(\".//DescriptiveMetadata/OfInterestTo\")\n",
    "        if tags:\n",
    "            tags = ', '.join([tag.get('FormalName') for tag in tags if tag.get('FormalName')])\n",
    "            news_data['Tags'] = tags.replace('--', ', ')\n",
    "        else:\n",
    "            news_data['Tags'] = None\n",
    "\n",
    "        # Extracting Date (FirstCreated)\n",
    "        date = root.find(\".//NewsManagement/FirstCreated\")\n",
    "        if date is not None:\n",
    "            date_text = date.text\n",
    "            try:\n",
    "                # First, try to parse without timezone assuming UTC ('Z' at the end)\n",
    "                datetime_obj = datetime.strptime(date_text, \"%Y%m%dT%H%M%SZ\")\n",
    "                datetime_obj = datetime_obj.replace(tzinfo=timezone.utc)\n",
    "            except ValueError:\n",
    "                # Next, try to parse with timezone offset\n",
    "                datetime_obj = datetime.strptime(date_text, \"%Y%m%dT%H%M%S%z\")\n",
    "                # Convert to UTC\n",
    "                datetime_obj = datetime_obj.astimezone(timezone.utc)\n",
    "\n",
    "            # Format the datetime object to ISO 8601 format in UTC\n",
    "            news_data['Date'] = datetime_obj.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "\n",
    "        # Extracting Location\n",
    "        location = root.find(\".//Location\")\n",
    "        if location is not None:\n",
    "            country = location.find(\".//Property[@FormalName='Country']\")\n",
    "            city = location.find(\".//Property[@FormalName='City']\")\n",
    "            location_text = ''\n",
    "            if city is not None:\n",
    "                location_text += city.get('Value')\n",
    "            if country is not None:\n",
    "                location_text += ', ' + country.get('Value') if location_text else country.get('Value')\n",
    "            news_data['Location'] = location_text\n",
    "\n",
    "        # TODO: Extract Authors and Content once their structure is understood\n",
    "            \n",
    "        # Extracting Authors\n",
    "        news_data['Authors'] = extract_author_or_provider(file_path)\n",
    "\n",
    "        # Extracting Content\n",
    "        news_data['Content'] = extract_content(root)\n",
    "\n",
    "        return news_data\n",
    "\n",
    "    except ET.ParseError:\n",
    "        return {'error': 'Failed to parse XML file'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 48 files in afp\\ARA_Media_SansSport\n",
      "Processed 26 files in afp\\arabic\\journal\\minaldounia\n",
      "Processed 22 files in afp\\arabic\\journal\\sport\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96 entries, 0 to 95\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Headline  96 non-null     object\n",
      " 1   Topic     96 non-null     object\n",
      " 2   Tags      47 non-null     object\n",
      " 3   Authors   95 non-null     object\n",
      " 4   Date      96 non-null     object\n",
      " 5   Content   96 non-null     object\n",
      " 6   Location  95 non-null     object\n",
      "dtypes: object(7)\n",
      "memory usage: 5.4+ KB\n"
     ]
    }
   ],
   "source": [
    "def process_xml_files_iteratively(folder_path):\n",
    "    \"\"\"\n",
    "    Iteratively searches through the folder tree for XML files, applies dummy_function to each,\n",
    "    and counts the number of files processed for each path.\n",
    "    \"\"\"\n",
    "    xml_count = {}\n",
    "    content_list = []\n",
    "    queue = deque([folder_path])  # Initialize the queue with the root folder\n",
    "\n",
    "    while queue:\n",
    "        current_path = queue.popleft()  # Get the next directory to process\n",
    "        current_count = 0\n",
    "\n",
    "        # Attempt to list directories and files in the current_path\n",
    "        try:\n",
    "            with os.scandir(current_path) as it:\n",
    "                for entry in it:\n",
    "                    if entry.is_dir():\n",
    "                        queue.append(entry.path)  # Add subdirectories to the queue\n",
    "                    elif entry.is_file() and entry.name.endswith('.xml'):\n",
    "                        content_list.append(parse_newsml_xml(entry.path))\n",
    "                        current_count += 1\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied: {current_path}\")\n",
    "\n",
    "        if current_count > 0:\n",
    "            xml_count[current_path] = current_count\n",
    "\n",
    "    for x in xml_count:\n",
    "        print(f'Processed {xml_count[x]} files in {x}')\n",
    "\n",
    "    df = pd.DataFrame(content_list)\n",
    "    return df\n",
    "\n",
    "content = process_xml_files_iteratively('afp')\n",
    "\n",
    "# Save to csv\n",
    "content.to_csv('parsed_xml.csv', index=False)\n",
    "\n",
    "content.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tags` are missing about half their entries. This is due to the data present in the XML files themselves. Unfortunately, the files in `afp\\ARA_Media_SansSport` don't have any information suitable to be used as tags. Otherwise, everything else has largely extracted. The odd missing values seem to be issues with the files themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>للكلاب مطعمها في روما</td>\n",
       "      <td>ايطاليا-حيوانات-اطعمة-مطعم-خدمة دنيا</td>\n",
       "      <td>arabic, journal, minaldounia</td>\n",
       "      <td>غيلداس لو رو</td>\n",
       "      <td>2023-11-26T12:01:45+0000</td>\n",
       "      <td>تسود مطعم \"فيوتو\" في روما أجواء مميزة، فالإضاء...</td>\n",
       "      <td>روما, ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>وصول الرهائن المفرج عنهم من غزة إلى الأراضي ال...</td>\n",
       "      <td>اسرائيل/فلسطينيون/مفقودون/نزاع</td>\n",
       "      <td>None</td>\n",
       "      <td>أ ف ب</td>\n",
       "      <td>2023-11-25T22:14:57+0000</td>\n",
       "      <td>أعلن الجيش الإسرائيلي أن المجموعة الثانية من ا...</td>\n",
       "      <td>القدس, ZZZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>دوري المحترفين: ايرفينغ ضد خطة الاستئناف في أو...</td>\n",
       "      <td>Basket-NBA-health-virus</td>\n",
       "      <td>arabic, journal, sport</td>\n",
       "      <td>مايك ستوبي</td>\n",
       "      <td>2020-06-13T22:29:35+0000</td>\n",
       "      <td>أكدت تقارير صحافية متعددة السبت أن كايري ايرفي...</td>\n",
       "      <td>نيويورك, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>شخصية افتراضية عبر لعبة \"فورتنايت\" لنجدة الأطف...</td>\n",
       "      <td>فرنسا-اطفال-استغلال-العاب-خدمة دنيا</td>\n",
       "      <td>arabic, journal, minaldounia</td>\n",
       "      <td>أرنو بوفييه</td>\n",
       "      <td>2020-06-15T13:48:34+0000</td>\n",
       "      <td>من خلال شخصية افتراضية مجنحة ترتدي الأزرق دخلت...</td>\n",
       "      <td>باريس, FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>حماس تعلن أنها أفرجت عن رهينة روسية وسلمتها ال...</td>\n",
       "      <td>تنبيه</td>\n",
       "      <td>None</td>\n",
       "      <td>أ ف ب</td>\n",
       "      <td>2023-11-26T14:41:54+0000</td>\n",
       "      <td>حماس تعلن أنها أفرجت عن رهينة روسية وسلمتها ال...</td>\n",
       "      <td>غزة, PSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>بطولة إسبانيا: برشلونة يدشن عودته إلى المنافسا...</td>\n",
       "      <td>قدم-إسبانيا-بطولة</td>\n",
       "      <td>arabic, journal, sport</td>\n",
       "      <td>خايمي رينا</td>\n",
       "      <td>2020-06-13T21:58:58+0000</td>\n",
       "      <td>دشَّن برشلونة المتصدر وحامل اللقب عودته إلى ال...</td>\n",
       "      <td>مدريد, ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>وصول الرهائن المفرج عنهم من قطاع غزة الى مصر (...</td>\n",
       "      <td>تنبيه</td>\n",
       "      <td>None</td>\n",
       "      <td>أ ف ب</td>\n",
       "      <td>2023-11-25T21:39:51+0000</td>\n",
       "      <td>وصول الرهائن المفرج عنهم من قطاع غزة الى مصر (...</td>\n",
       "      <td>القاهرة, EGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>كييف تؤكد إسقاط 71 مسيّرة روسية ليل الجمعة السبت</td>\n",
       "      <td>تنبيه</td>\n",
       "      <td>None</td>\n",
       "      <td>أ ف ب</td>\n",
       "      <td>2023-11-25T07:36:54+0000</td>\n",
       "      <td>كييف تؤكد إسقاط 71 مسيّرة روسية ليل الجمعة الس...</td>\n",
       "      <td>كييف, UKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>الألعاب الآسيوية تشعل الحلم الأولمبي للرياضات ...</td>\n",
       "      <td>اسياد-كمبيوتر-2023-2022-اندونيسيا-العاب</td>\n",
       "      <td>arabic, journal, sport</td>\n",
       "      <td>فيصل كمال وسونغهي هوانغ</td>\n",
       "      <td>2023-09-19T05:59:38+0000</td>\n",
       "      <td>شكّل إدراج الرياضات الإلكترونية كمسابقة رسمية ...</td>\n",
       "      <td>نيودلهي, IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>هجوم المسيّرات الروسية كان الأكبر على كييف منذ...</td>\n",
       "      <td>تنبيه</td>\n",
       "      <td>None</td>\n",
       "      <td>أ ف ب</td>\n",
       "      <td>2023-11-25T07:41:03+0000</td>\n",
       "      <td>هجوم المسيّرات الروسية كان الأكبر على كييف منذ...</td>\n",
       "      <td>كييف, UKR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline  \\\n",
       "65                              للكلاب مطعمها في روما   \n",
       "20  وصول الرهائن المفرج عنهم من غزة إلى الأراضي ال...   \n",
       "74  دوري المحترفين: ايرفينغ ضد خطة الاستئناف في أو...   \n",
       "56  شخصية افتراضية عبر لعبة \"فورتنايت\" لنجدة الأطف...   \n",
       "33  حماس تعلن أنها أفرجت عن رهينة روسية وسلمتها ال...   \n",
       "75  بطولة إسبانيا: برشلونة يدشن عودته إلى المنافسا...   \n",
       "19  وصول الرهائن المفرج عنهم من قطاع غزة الى مصر (...   \n",
       "6    كييف تؤكد إسقاط 71 مسيّرة روسية ليل الجمعة السبت   \n",
       "84  الألعاب الآسيوية تشعل الحلم الأولمبي للرياضات ...   \n",
       "7   هجوم المسيّرات الروسية كان الأكبر على كييف منذ...   \n",
       "\n",
       "                                      Topic                          Tags  \\\n",
       "65     ايطاليا-حيوانات-اطعمة-مطعم-خدمة دنيا  arabic, journal, minaldounia   \n",
       "20           اسرائيل/فلسطينيون/مفقودون/نزاع                          None   \n",
       "74                  Basket-NBA-health-virus        arabic, journal, sport   \n",
       "56      فرنسا-اطفال-استغلال-العاب-خدمة دنيا  arabic, journal, minaldounia   \n",
       "33                                    تنبيه                          None   \n",
       "75                        قدم-إسبانيا-بطولة        arabic, journal, sport   \n",
       "19                                    تنبيه                          None   \n",
       "6                                     تنبيه                          None   \n",
       "84  اسياد-كمبيوتر-2023-2022-اندونيسيا-العاب        arabic, journal, sport   \n",
       "7                                     تنبيه                          None   \n",
       "\n",
       "                    Authors                      Date  \\\n",
       "65             غيلداس لو رو  2023-11-26T12:01:45+0000   \n",
       "20                    أ ف ب  2023-11-25T22:14:57+0000   \n",
       "74               مايك ستوبي  2020-06-13T22:29:35+0000   \n",
       "56              أرنو بوفييه  2020-06-15T13:48:34+0000   \n",
       "33                    أ ف ب  2023-11-26T14:41:54+0000   \n",
       "75               خايمي رينا  2020-06-13T21:58:58+0000   \n",
       "19                    أ ف ب  2023-11-25T21:39:51+0000   \n",
       "6                     أ ف ب  2023-11-25T07:36:54+0000   \n",
       "84  فيصل كمال وسونغهي هوانغ  2023-09-19T05:59:38+0000   \n",
       "7                     أ ف ب  2023-11-25T07:41:03+0000   \n",
       "\n",
       "                                              Content      Location  \n",
       "65  تسود مطعم \"فيوتو\" في روما أجواء مميزة، فالإضاء...     روما, ITA  \n",
       "20  أعلن الجيش الإسرائيلي أن المجموعة الثانية من ا...    القدس, ZZZ  \n",
       "74  أكدت تقارير صحافية متعددة السبت أن كايري ايرفي...  نيويورك, USA  \n",
       "56  من خلال شخصية افتراضية مجنحة ترتدي الأزرق دخلت...    باريس, FRA  \n",
       "33  حماس تعلن أنها أفرجت عن رهينة روسية وسلمتها ال...      غزة, PSE  \n",
       "75  دشَّن برشلونة المتصدر وحامل اللقب عودته إلى ال...    مدريد, ESP  \n",
       "19  وصول الرهائن المفرج عنهم من قطاع غزة الى مصر (...  القاهرة, EGY  \n",
       "6   كييف تؤكد إسقاط 71 مسيّرة روسية ليل الجمعة الس...     كييف, UKR  \n",
       "84  شكّل إدراج الرياضات الإلكترونية كمسابقة رسمية ...  نيودلهي, IND  \n",
       "7   هجوم المسيّرات الروسية كان الأكبر على كييف منذ...     كييف, UKR  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = content.sample(10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't speak/understand Arabic. I can tell that matches the contents in the original files, but it would be better to see if the extractions make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating to English\n",
    "\n",
    "I'm going to use [OpenAI](https://openai.com/) to translate the text to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Content</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Dogs have their restaurant in Rome.</td>\n",
       "      <td>Italy-animals-food-restaurant-world service</td>\n",
       "      <td>Arabic, journal, from the world.</td>\n",
       "      <td>Guildas Law Ro</td>\n",
       "      <td>The \"Fido\" restaurant in Rome has a unique atm...</td>\n",
       "      <td>Rome, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The released hostages from Gaza have arrived i...</td>\n",
       "      <td>Israel/Palestinians/Missing/Conflict</td>\n",
       "      <td></td>\n",
       "      <td>AFP</td>\n",
       "      <td>The Israeli army announced that the second gro...</td>\n",
       "      <td>Jerusalem, ZZZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Professional League: Irving against the restar...</td>\n",
       "      <td>Basketball-NBA-health-virus</td>\n",
       "      <td>Arabic, journal, sport</td>\n",
       "      <td>Mike Stuby</td>\n",
       "      <td>Multiple news reports on Saturday confirmed th...</td>\n",
       "      <td>New York, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Virtual character through the game \"Fortnite\" ...</td>\n",
       "      <td>France - Children - Exploitation - Games - Dun...</td>\n",
       "      <td>Arabic, journal, from the world.</td>\n",
       "      <td>Arno buffet</td>\n",
       "      <td>Through a virtual character wearing blue wings...</td>\n",
       "      <td>Paris, FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Hamas announces that it has released a Russian...</td>\n",
       "      <td>Warning</td>\n",
       "      <td></td>\n",
       "      <td>AFP</td>\n",
       "      <td>Hamas announces that it has released a Russian...</td>\n",
       "      <td>Gaza, PSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Spanish Championship: Barcelona starts its com...</td>\n",
       "      <td>Spain hosted the championship.</td>\n",
       "      <td>العربية، مجلة، رياضة\\n\\nArabic, journal, sport</td>\n",
       "      <td>Khaimi Rina</td>\n",
       "      <td>Barcelona, ​​the leader and defending champion...</td>\n",
       "      <td>Madrid, ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The released hostages from Gaza have arrived i...</td>\n",
       "      <td>Warning</td>\n",
       "      <td></td>\n",
       "      <td>AFP</td>\n",
       "      <td>The released hostages from Gaza have arrived i...</td>\n",
       "      <td>Cairo, EGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How to confirm the downing of 71 Russian drone...</td>\n",
       "      <td>Warning</td>\n",
       "      <td></td>\n",
       "      <td>AFP</td>\n",
       "      <td>How do you confirm the downing of 71 Russian d...</td>\n",
       "      <td>Kyiv, Ukraine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>The Asian Games ignite the Olympic dream for e...</td>\n",
       "      <td>Masters-Computer-2023-2022-Indonesia-Games</td>\n",
       "      <td>Arabic, journal, sport</td>\n",
       "      <td>Faisal Kamal and Songhee Huang</td>\n",
       "      <td>The inclusion of esports as an official compet...</td>\n",
       "      <td>New Delhi, IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Russian drone attack was the largest on Ky...</td>\n",
       "      <td>Warning</td>\n",
       "      <td></td>\n",
       "      <td>AFP</td>\n",
       "      <td>The Russian drone attack on Kiev was the large...</td>\n",
       "      <td>Kyiv, Ukraine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline  \\\n",
       "65                Dogs have their restaurant in Rome.   \n",
       "20  The released hostages from Gaza have arrived i...   \n",
       "74  Professional League: Irving against the restar...   \n",
       "56  Virtual character through the game \"Fortnite\" ...   \n",
       "33  Hamas announces that it has released a Russian...   \n",
       "75  Spanish Championship: Barcelona starts its com...   \n",
       "19  The released hostages from Gaza have arrived i...   \n",
       "6   How to confirm the downing of 71 Russian drone...   \n",
       "84  The Asian Games ignite the Olympic dream for e...   \n",
       "7   The Russian drone attack was the largest on Ky...   \n",
       "\n",
       "                                                Topic  \\\n",
       "65        Italy-animals-food-restaurant-world service   \n",
       "20               Israel/Palestinians/Missing/Conflict   \n",
       "74                        Basketball-NBA-health-virus   \n",
       "56  France - Children - Exploitation - Games - Dun...   \n",
       "33                                            Warning   \n",
       "75                     Spain hosted the championship.   \n",
       "19                                            Warning   \n",
       "6                                             Warning   \n",
       "84         Masters-Computer-2023-2022-Indonesia-Games   \n",
       "7                                             Warning   \n",
       "\n",
       "                                              Tags  \\\n",
       "65                Arabic, journal, from the world.   \n",
       "20                                                   \n",
       "74                          Arabic, journal, sport   \n",
       "56                Arabic, journal, from the world.   \n",
       "33                                                   \n",
       "75  العربية، مجلة، رياضة\\n\\nArabic, journal, sport   \n",
       "19                                                   \n",
       "6                                                    \n",
       "84                          Arabic, journal, sport   \n",
       "7                                                    \n",
       "\n",
       "                           Authors  \\\n",
       "65                  Guildas Law Ro   \n",
       "20                             AFP   \n",
       "74                      Mike Stuby   \n",
       "56                     Arno buffet   \n",
       "33                             AFP   \n",
       "75                     Khaimi Rina   \n",
       "19                             AFP   \n",
       "6                              AFP   \n",
       "84  Faisal Kamal and Songhee Huang   \n",
       "7                              AFP   \n",
       "\n",
       "                                              Content        Location  \n",
       "65  The \"Fido\" restaurant in Rome has a unique atm...     Rome, Italy  \n",
       "20  The Israeli army announced that the second gro...  Jerusalem, ZZZ  \n",
       "74  Multiple news reports on Saturday confirmed th...   New York, USA  \n",
       "56  Through a virtual character wearing blue wings...      Paris, FRA  \n",
       "33  Hamas announces that it has released a Russian...       Gaza, PSE  \n",
       "75  Barcelona, ​​the leader and defending champion...     Madrid, ESP  \n",
       "19  The released hostages from Gaza have arrived i...      Cairo, EGY  \n",
       "6   How do you confirm the downing of 71 Russian d...  Kyiv, Ukraine.  \n",
       "84  The inclusion of esports as an official compet...  New Delhi, IND  \n",
       "7   The Russian drone attack on Kiev was the large...   Kyiv, Ukraine  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def translate_to_english(text):\n",
    "    # Check if the text is null\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Create a conversation with the model\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"You are a helpful assistant that \\\n",
    "            translates any text to English. Return only the translated text\\\n",
    "             do not comment about it\"},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    )\n",
    "    # Extract the assistant's reply\n",
    "    translation = response['choices'][0]['message']['content']\n",
    "    return translation\n",
    "\n",
    "translated_df = sample.drop('Date', axis=1).applymap(translate_to_english)\n",
    "translated_df.to_csv('translated_sample.csv', index=False)\n",
    "translated_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
